{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jrossonrinehart/AI_Assignment7/blob/main/metaltest1%20(Graphs%20for%20both%20files%20are%20in%20here).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "metrics from metaltest2\n",
        "\n",
        "GPU - Training Time = 98.96444249153137s Accuracy 87.3%\n",
        "\n",
        "CPU - Training Time = 224.139s Accuracy 88.0%"
      ],
      "metadata": {
        "id": "62tbYijbSSQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "4gYIg1-iSbTV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#metaltest1 CPU\n",
        "plt.scatter(1.780, 80.9)\n",
        "#metaltest1 GPU\n",
        "plt.scatter( 1.662,81)\n",
        "\n",
        "plt.text(1.780, 80.9, \"mt1 CPU\")\n",
        "plt.text(1.662, 81, \"mt1 GPU\")\n",
        "plt.xlabel(\"time in seconds\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "_eWfJi6xSi0f",
        "outputId": "c6f32708-1d52-4926-ce0c-e22e5e6aa1cb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#metaltest2 CPU\n",
        "plt.scatter(224.139, 88)\n",
        "#metaltest2 GPU\n",
        "plt.scatter(98.964,87.3)\n",
        "\n",
        "plt.text(224.139, 88, \"mt2 CPU\")\n",
        "plt.text(98.964,87.3, \"mt2 GPU\")\n",
        "plt.xlabel(\"time in seconds\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "Ik3qbdLKUrc4",
        "outputId": "f829ed1a-7c54-44e2-9c2c-6e48690ce16c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CPU Run"
      ],
      "metadata": {
        "id": "E1UshHqbBjQh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzeLeqEaNj8v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40955c60-a953-4067-bd5e-195388662d3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 18195857.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 348809.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 6158902.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 2168988.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n",
            "starting timer for training using CPU...\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.297027  [   64/60000]\n",
            "loss: 2.289112  [ 6464/60000]\n",
            "loss: 2.272602  [12864/60000]\n",
            "loss: 2.266188  [19264/60000]\n",
            "loss: 2.243844  [25664/60000]\n",
            "loss: 2.229522  [32064/60000]\n",
            "loss: 2.235333  [38464/60000]\n",
            "loss: 2.210760  [44864/60000]\n",
            "loss: 2.202165  [51264/60000]\n",
            "loss: 2.169469  [57664/60000]\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.175094  [   64/60000]\n",
            "loss: 2.167756  [ 6464/60000]\n",
            "loss: 2.116666  [12864/60000]\n",
            "loss: 2.125790  [19264/60000]\n",
            "loss: 2.078140  [25664/60000]\n",
            "loss: 2.027013  [32064/60000]\n",
            "loss: 2.050354  [38464/60000]\n",
            "loss: 1.982969  [44864/60000]\n",
            "loss: 1.984258  [51264/60000]\n",
            "loss: 1.908330  [57664/60000]\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.937564  [   64/60000]\n",
            "loss: 1.913983  [ 6464/60000]\n",
            "loss: 1.802631  [12864/60000]\n",
            "loss: 1.835114  [19264/60000]\n",
            "loss: 1.734719  [25664/60000]\n",
            "loss: 1.675512  [32064/60000]\n",
            "loss: 1.693411  [38464/60000]\n",
            "loss: 1.597608  [44864/60000]\n",
            "loss: 1.621758  [51264/60000]\n",
            "loss: 1.508337  [57664/60000]\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.593578  [   64/60000]\n",
            "loss: 1.561107  [ 6464/60000]\n",
            "loss: 1.413445  [12864/60000]\n",
            "loss: 1.478043  [19264/60000]\n",
            "loss: 1.369131  [25664/60000]\n",
            "loss: 1.350028  [32064/60000]\n",
            "loss: 1.361194  [38464/60000]\n",
            "loss: 1.290291  [44864/60000]\n",
            "loss: 1.327106  [51264/60000]\n",
            "loss: 1.223570  [57664/60000]\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.327202  [   64/60000]\n",
            "loss: 1.312149  [ 6464/60000]\n",
            "loss: 1.150183  [12864/60000]\n",
            "loss: 1.248177  [19264/60000]\n",
            "loss: 1.131464  [25664/60000]\n",
            "loss: 1.145833  [32064/60000]\n",
            "loss: 1.163788  [38464/60000]\n",
            "loss: 1.108423  [44864/60000]\n",
            "loss: 1.147049  [51264/60000]\n",
            "loss: 1.067395  [57664/60000]\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.154071  [   64/60000]\n",
            "loss: 1.162317  [ 6464/60000]\n",
            "loss: 0.983462  [12864/60000]\n",
            "loss: 1.109288  [19264/60000]\n",
            "loss: 0.989082  [25664/60000]\n",
            "loss: 1.012908  [32064/60000]\n",
            "loss: 1.045335  [38464/60000]\n",
            "loss: 0.995047  [44864/60000]\n",
            "loss: 1.031983  [51264/60000]\n",
            "loss: 0.973317  [57664/60000]\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.036855  [   64/60000]\n",
            "loss: 1.067946  [ 6464/60000]\n",
            "loss: 0.870968  [12864/60000]\n",
            "loss: 1.018226  [19264/60000]\n",
            "loss: 0.900813  [25664/60000]\n",
            "loss: 0.920225  [32064/60000]\n",
            "loss: 0.968443  [38464/60000]\n",
            "loss: 0.920467  [44864/60000]\n",
            "loss: 0.952689  [51264/60000]\n",
            "loss: 0.910904  [57664/60000]\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.950975  [   64/60000]\n",
            "loss: 1.002142  [ 6464/60000]\n",
            "loss: 0.789323  [12864/60000]\n",
            "loss: 0.953519  [19264/60000]\n",
            "loss: 0.841400  [25664/60000]\n",
            "loss: 0.852420  [32064/60000]\n",
            "loss: 0.914047  [38464/60000]\n",
            "loss: 0.869428  [44864/60000]\n",
            "loss: 0.895434  [51264/60000]\n",
            "loss: 0.865459  [57664/60000]\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.884584  [   64/60000]\n",
            "loss: 0.952223  [ 6464/60000]\n",
            "loss: 0.727731  [12864/60000]\n",
            "loss: 0.904925  [19264/60000]\n",
            "loss: 0.798741  [25664/60000]\n",
            "loss: 0.801493  [32064/60000]\n",
            "loss: 0.872767  [38464/60000]\n",
            "loss: 0.833189  [44864/60000]\n",
            "loss: 0.852563  [51264/60000]\n",
            "loss: 0.830196  [57664/60000]\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.831134  [   64/60000]\n",
            "loss: 0.911603  [ 6464/60000]\n",
            "loss: 0.679338  [12864/60000]\n",
            "loss: 0.867007  [19264/60000]\n",
            "loss: 0.766129  [25664/60000]\n",
            "loss: 0.762279  [32064/60000]\n",
            "loss: 0.839047  [38464/60000]\n",
            "loss: 0.806115  [44864/60000]\n",
            "loss: 0.819362  [51264/60000]\n",
            "loss: 0.801354  [57664/60000]\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.786963  [   64/60000]\n",
            "loss: 0.876662  [ 6464/60000]\n",
            "loss: 0.640173  [12864/60000]\n",
            "loss: 0.836309  [19264/60000]\n",
            "loss: 0.740011  [25664/60000]\n",
            "loss: 0.731476  [32064/60000]\n",
            "loss: 0.810063  [38464/60000]\n",
            "loss: 0.784599  [44864/60000]\n",
            "loss: 0.792804  [51264/60000]\n",
            "loss: 0.776895  [57664/60000]\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.749471  [   64/60000]\n",
            "loss: 0.845538  [ 6464/60000]\n",
            "loss: 0.607586  [12864/60000]\n",
            "loss: 0.810953  [19264/60000]\n",
            "loss: 0.718395  [25664/60000]\n",
            "loss: 0.706779  [32064/60000]\n",
            "loss: 0.784152  [38464/60000]\n",
            "loss: 0.766613  [44864/60000]\n",
            "loss: 0.770882  [51264/60000]\n",
            "loss: 0.755548  [57664/60000]\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.717155  [   64/60000]\n",
            "loss: 0.817354  [ 6464/60000]\n",
            "loss: 0.579748  [12864/60000]\n",
            "loss: 0.789567  [19264/60000]\n",
            "loss: 0.700001  [25664/60000]\n",
            "loss: 0.686511  [32064/60000]\n",
            "loss: 0.760409  [38464/60000]\n",
            "loss: 0.750982  [44864/60000]\n",
            "loss: 0.752340  [51264/60000]\n",
            "loss: 0.736565  [57664/60000]\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.688815  [   64/60000]\n",
            "loss: 0.791466  [ 6464/60000]\n",
            "loss: 0.555604  [12864/60000]\n",
            "loss: 0.771071  [19264/60000]\n",
            "loss: 0.684082  [25664/60000]\n",
            "loss: 0.669445  [32064/60000]\n",
            "loss: 0.738436  [38464/60000]\n",
            "loss: 0.737031  [44864/60000]\n",
            "loss: 0.736516  [51264/60000]\n",
            "loss: 0.719256  [57664/60000]\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.663773  [   64/60000]\n",
            "loss: 0.767736  [ 6464/60000]\n",
            "loss: 0.534503  [12864/60000]\n",
            "loss: 0.754945  [19264/60000]\n",
            "loss: 0.670200  [25664/60000]\n",
            "loss: 0.654863  [32064/60000]\n",
            "loss: 0.717957  [38464/60000]\n",
            "loss: 0.724614  [44864/60000]\n",
            "loss: 0.722647  [51264/60000]\n",
            "loss: 0.703293  [57664/60000]\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.641556  [   64/60000]\n",
            "loss: 0.745888  [ 6464/60000]\n",
            "loss: 0.515962  [12864/60000]\n",
            "loss: 0.740684  [19264/60000]\n",
            "loss: 0.658037  [25664/60000]\n",
            "loss: 0.642350  [32064/60000]\n",
            "loss: 0.698934  [38464/60000]\n",
            "loss: 0.713480  [44864/60000]\n",
            "loss: 0.710443  [51264/60000]\n",
            "loss: 0.688548  [57664/60000]\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.621833  [   64/60000]\n",
            "loss: 0.725851  [ 6464/60000]\n",
            "loss: 0.499507  [12864/60000]\n",
            "loss: 0.727789  [19264/60000]\n",
            "loss: 0.647231  [25664/60000]\n",
            "loss: 0.631542  [32064/60000]\n",
            "loss: 0.681251  [38464/60000]\n",
            "loss: 0.703707  [44864/60000]\n",
            "loss: 0.699753  [51264/60000]\n",
            "loss: 0.674865  [57664/60000]\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.604248  [   64/60000]\n",
            "loss: 0.707521  [ 6464/60000]\n",
            "loss: 0.484826  [12864/60000]\n",
            "loss: 0.716004  [19264/60000]\n",
            "loss: 0.637594  [25664/60000]\n",
            "loss: 0.622113  [32064/60000]\n",
            "loss: 0.664874  [38464/60000]\n",
            "loss: 0.695155  [44864/60000]\n",
            "loss: 0.690442  [51264/60000]\n",
            "loss: 0.662116  [57664/60000]\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.588492  [   64/60000]\n",
            "loss: 0.690814  [ 6464/60000]\n",
            "loss: 0.471642  [12864/60000]\n",
            "loss: 0.705180  [19264/60000]\n",
            "loss: 0.629017  [25664/60000]\n",
            "loss: 0.613813  [32064/60000]\n",
            "loss: 0.649616  [38464/60000]\n",
            "loss: 0.687852  [44864/60000]\n",
            "loss: 0.682424  [51264/60000]\n",
            "loss: 0.650193  [57664/60000]\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.574331  [   64/60000]\n",
            "loss: 0.675594  [ 6464/60000]\n",
            "loss: 0.459756  [12864/60000]\n",
            "loss: 0.695247  [19264/60000]\n",
            "loss: 0.621272  [25664/60000]\n",
            "loss: 0.606522  [32064/60000]\n",
            "loss: 0.635580  [38464/60000]\n",
            "loss: 0.681718  [44864/60000]\n",
            "loss: 0.675479  [51264/60000]\n",
            "loss: 0.639076  [57664/60000]\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.561542  [   64/60000]\n",
            "loss: 0.661687  [ 6464/60000]\n",
            "loss: 0.448923  [12864/60000]\n",
            "loss: 0.685967  [19264/60000]\n",
            "loss: 0.614051  [25664/60000]\n",
            "loss: 0.600043  [32064/60000]\n",
            "loss: 0.622589  [38464/60000]\n",
            "loss: 0.676612  [44864/60000]\n",
            "loss: 0.669528  [51264/60000]\n",
            "loss: 0.628636  [57664/60000]\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.549903  [   64/60000]\n",
            "loss: 0.648997  [ 6464/60000]\n",
            "loss: 0.439005  [12864/60000]\n",
            "loss: 0.677262  [19264/60000]\n",
            "loss: 0.607328  [25664/60000]\n",
            "loss: 0.594052  [32064/60000]\n",
            "loss: 0.610549  [38464/60000]\n",
            "loss: 0.672449  [44864/60000]\n",
            "loss: 0.664561  [51264/60000]\n",
            "loss: 0.618742  [57664/60000]\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.539228  [   64/60000]\n",
            "loss: 0.637438  [ 6464/60000]\n",
            "loss: 0.429915  [12864/60000]\n",
            "loss: 0.669142  [19264/60000]\n",
            "loss: 0.600856  [25664/60000]\n",
            "loss: 0.588535  [32064/60000]\n",
            "loss: 0.599425  [38464/60000]\n",
            "loss: 0.669058  [44864/60000]\n",
            "loss: 0.660214  [51264/60000]\n",
            "loss: 0.609284  [57664/60000]\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.529308  [   64/60000]\n",
            "loss: 0.626804  [ 6464/60000]\n",
            "loss: 0.421575  [12864/60000]\n",
            "loss: 0.661477  [19264/60000]\n",
            "loss: 0.594675  [25664/60000]\n",
            "loss: 0.583404  [32064/60000]\n",
            "loss: 0.589125  [38464/60000]\n",
            "loss: 0.666402  [44864/60000]\n",
            "loss: 0.656489  [51264/60000]\n",
            "loss: 0.600275  [57664/60000]\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.519958  [   64/60000]\n",
            "loss: 0.616995  [ 6464/60000]\n",
            "loss: 0.413892  [12864/60000]\n",
            "loss: 0.654238  [19264/60000]\n",
            "loss: 0.588675  [25664/60000]\n",
            "loss: 0.578575  [32064/60000]\n",
            "loss: 0.579641  [38464/60000]\n",
            "loss: 0.664401  [44864/60000]\n",
            "loss: 0.653282  [51264/60000]\n",
            "loss: 0.591546  [57664/60000]\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.511182  [   64/60000]\n",
            "loss: 0.607927  [ 6464/60000]\n",
            "loss: 0.406768  [12864/60000]\n",
            "loss: 0.647378  [19264/60000]\n",
            "loss: 0.582704  [25664/60000]\n",
            "loss: 0.573903  [32064/60000]\n",
            "loss: 0.570901  [38464/60000]\n",
            "loss: 0.662995  [44864/60000]\n",
            "loss: 0.650470  [51264/60000]\n",
            "loss: 0.583059  [57664/60000]\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.502913  [   64/60000]\n",
            "loss: 0.599530  [ 6464/60000]\n",
            "loss: 0.400112  [12864/60000]\n",
            "loss: 0.640834  [19264/60000]\n",
            "loss: 0.576803  [25664/60000]\n",
            "loss: 0.569346  [32064/60000]\n",
            "loss: 0.562790  [38464/60000]\n",
            "loss: 0.662090  [44864/60000]\n",
            "loss: 0.647961  [51264/60000]\n",
            "loss: 0.574892  [57664/60000]\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.495144  [   64/60000]\n",
            "loss: 0.591744  [ 6464/60000]\n",
            "loss: 0.393903  [12864/60000]\n",
            "loss: 0.634636  [19264/60000]\n",
            "loss: 0.570956  [25664/60000]\n",
            "loss: 0.564916  [32064/60000]\n",
            "loss: 0.555317  [38464/60000]\n",
            "loss: 0.661615  [44864/60000]\n",
            "loss: 0.645635  [51264/60000]\n",
            "loss: 0.566927  [57664/60000]\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.487695  [   64/60000]\n",
            "loss: 0.584519  [ 6464/60000]\n",
            "loss: 0.388101  [12864/60000]\n",
            "loss: 0.628665  [19264/60000]\n",
            "loss: 0.565149  [25664/60000]\n",
            "loss: 0.560538  [32064/60000]\n",
            "loss: 0.548392  [38464/60000]\n",
            "loss: 0.661520  [44864/60000]\n",
            "loss: 0.643415  [51264/60000]\n",
            "loss: 0.559097  [57664/60000]\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.480585  [   64/60000]\n",
            "loss: 0.577757  [ 6464/60000]\n",
            "loss: 0.382670  [12864/60000]\n",
            "loss: 0.622937  [19264/60000]\n",
            "loss: 0.559377  [25664/60000]\n",
            "loss: 0.556189  [32064/60000]\n",
            "loss: 0.541935  [38464/60000]\n",
            "loss: 0.661703  [44864/60000]\n",
            "loss: 0.641346  [51264/60000]\n",
            "loss: 0.551539  [57664/60000]\n",
            "completed training in ... 322.67236137390137s\n",
            "starting timer for testing using CPU...\n",
            "Test Error: \n",
            " Accuracy: 80.9%, Avg loss: 0.551765 \n",
            "\n",
            "completed testing in ... 1.7796175479888916s\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import time\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Define linear model we will use below\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer, device):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn, device):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "# modified from https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
        "# get our competing devices ready ... go ahead and init all three here, but ONLY USE ONE during each test\n",
        "# scroll down below and replace the references to gpu_, tpu_, cpu with whichever device you are testing\n",
        "# make sure you replace ALL of them\n",
        "gpu_device = torch.device(\"cuda\")\n",
        "tpu_device = torch.device(\"xla\")\n",
        "cpu_device = torch.device(\"cpu\")\n",
        "\n",
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# first hyperparam\n",
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "# Show some sample data\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break\n",
        "\n",
        "\n",
        "# sample code for working with m1\n",
        "  # Create a Tensor directly on the mps device\n",
        "  #x = torch.ones(5, device=mps_device)\n",
        "  # Or\n",
        "  #x = torch.ones(5, device=\"mps\")\n",
        "  # Any operation happens on the GPU\n",
        "  #y = x * 2\n",
        "\n",
        "  # Move your model to mps just like any other device\n",
        "model = NeuralNetwork().to(device=cpu_device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "print(\"starting timer for training using CPU...\")\n",
        "start = time.time()\n",
        "epochs = 30 \n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer, device=cpu_device)\n",
        "print(f\"completed training in ... {time.time()-start}s\")\n",
        "\n",
        "print(\"starting timer for testing using CPU...\")\n",
        "start = time.time()\n",
        "test(test_dataloader, model, loss_fn, device=cpu_device)\n",
        "print(f\"completed testing in ... {time.time()-start}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GPU Run"
      ],
      "metadata": {
        "id": "Qk_X2rNOBoBF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "405539cd-661c-4cf0-bd66-55202a35321d",
        "id": "ue6pXiQlBhRR"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:00<00:00, 110250300.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 4889020.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 58355089.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 16259244.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n",
            "starting timer for training using CPU...\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.308863  [   64/60000]\n",
            "loss: 2.298727  [ 6464/60000]\n",
            "loss: 2.276380  [12864/60000]\n",
            "loss: 2.267447  [19264/60000]\n",
            "loss: 2.264991  [25664/60000]\n",
            "loss: 2.223901  [32064/60000]\n",
            "loss: 2.233513  [38464/60000]\n",
            "loss: 2.204177  [44864/60000]\n",
            "loss: 2.197183  [51264/60000]\n",
            "loss: 2.162914  [57664/60000]\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.167871  [   64/60000]\n",
            "loss: 2.157590  [ 6464/60000]\n",
            "loss: 2.098866  [12864/60000]\n",
            "loss: 2.116066  [19264/60000]\n",
            "loss: 2.077002  [25664/60000]\n",
            "loss: 2.011971  [32064/60000]\n",
            "loss: 2.039972  [38464/60000]\n",
            "loss: 1.965366  [44864/60000]\n",
            "loss: 1.962523  [51264/60000]\n",
            "loss: 1.895414  [57664/60000]\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.917456  [   64/60000]\n",
            "loss: 1.886044  [ 6464/60000]\n",
            "loss: 1.768894  [12864/60000]\n",
            "loss: 1.814316  [19264/60000]\n",
            "loss: 1.717117  [25664/60000]\n",
            "loss: 1.659070  [32064/60000]\n",
            "loss: 1.680941  [38464/60000]\n",
            "loss: 1.584370  [44864/60000]\n",
            "loss: 1.598196  [51264/60000]\n",
            "loss: 1.509137  [57664/60000]\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.575679  [   64/60000]\n",
            "loss: 1.544833  [ 6464/60000]\n",
            "loss: 1.394560  [12864/60000]\n",
            "loss: 1.475158  [19264/60000]\n",
            "loss: 1.368745  [25664/60000]\n",
            "loss: 1.354823  [32064/60000]\n",
            "loss: 1.372248  [38464/60000]\n",
            "loss: 1.298106  [44864/60000]\n",
            "loss: 1.324878  [51264/60000]\n",
            "loss: 1.243986  [57664/60000]\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.327950  [   64/60000]\n",
            "loss: 1.311768  [ 6464/60000]\n",
            "loss: 1.145985  [12864/60000]\n",
            "loss: 1.256382  [19264/60000]\n",
            "loss: 1.142557  [25664/60000]\n",
            "loss: 1.159313  [32064/60000]\n",
            "loss: 1.184446  [38464/60000]\n",
            "loss: 1.121523  [44864/60000]\n",
            "loss: 1.151754  [51264/60000]\n",
            "loss: 1.087067  [57664/60000]\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.160950  [   64/60000]\n",
            "loss: 1.164389  [ 6464/60000]\n",
            "loss: 0.981442  [12864/60000]\n",
            "loss: 1.116126  [19264/60000]\n",
            "loss: 0.999039  [25664/60000]\n",
            "loss: 1.025140  [32064/60000]\n",
            "loss: 1.064889  [38464/60000]\n",
            "loss: 1.006875  [44864/60000]\n",
            "loss: 1.034586  [51264/60000]\n",
            "loss: 0.985606  [57664/60000]\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.042662  [   64/60000]\n",
            "loss: 1.067435  [ 6464/60000]\n",
            "loss: 0.866955  [12864/60000]\n",
            "loss: 1.021347  [19264/60000]\n",
            "loss: 0.905846  [25664/60000]\n",
            "loss: 0.928956  [32064/60000]\n",
            "loss: 0.985111  [38464/60000]\n",
            "loss: 0.931070  [44864/60000]\n",
            "loss: 0.951835  [51264/60000]\n",
            "loss: 0.916467  [57664/60000]\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.954447  [   64/60000]\n",
            "loss: 0.999896  [ 6464/60000]\n",
            "loss: 0.783890  [12864/60000]\n",
            "loss: 0.954140  [19264/60000]\n",
            "loss: 0.842850  [25664/60000]\n",
            "loss: 0.858099  [32064/60000]\n",
            "loss: 0.928658  [38464/60000]\n",
            "loss: 0.880039  [44864/60000]\n",
            "loss: 0.892149  [51264/60000]\n",
            "loss: 0.866177  [57664/60000]\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.886350  [   64/60000]\n",
            "loss: 0.948914  [ 6464/60000]\n",
            "loss: 0.721025  [12864/60000]\n",
            "loss: 0.903946  [19264/60000]\n",
            "loss: 0.797723  [25664/60000]\n",
            "loss: 0.804738  [32064/60000]\n",
            "loss: 0.885962  [38464/60000]\n",
            "loss: 0.844474  [44864/60000]\n",
            "loss: 0.847852  [51264/60000]\n",
            "loss: 0.827664  [57664/60000]\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.831918  [   64/60000]\n",
            "loss: 0.907807  [ 6464/60000]\n",
            "loss: 0.672143  [12864/60000]\n",
            "loss: 0.865574  [19264/60000]\n",
            "loss: 0.763003  [25664/60000]\n",
            "loss: 0.763619  [32064/60000]\n",
            "loss: 0.851797  [38464/60000]\n",
            "loss: 0.818401  [44864/60000]\n",
            "loss: 0.813632  [51264/60000]\n",
            "loss: 0.796725  [57664/60000]\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.786879  [   64/60000]\n",
            "loss: 0.872831  [ 6464/60000]\n",
            "loss: 0.632824  [12864/60000]\n",
            "loss: 0.835363  [19264/60000]\n",
            "loss: 0.734853  [25664/60000]\n",
            "loss: 0.731230  [32064/60000]\n",
            "loss: 0.822902  [38464/60000]\n",
            "loss: 0.798006  [44864/60000]\n",
            "loss: 0.786255  [51264/60000]\n",
            "loss: 0.770908  [57664/60000]\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.748424  [   64/60000]\n",
            "loss: 0.841969  [ 6464/60000]\n",
            "loss: 0.600137  [12864/60000]\n",
            "loss: 0.810876  [19264/60000]\n",
            "loss: 0.711204  [25664/60000]\n",
            "loss: 0.705064  [32064/60000]\n",
            "loss: 0.797202  [38464/60000]\n",
            "loss: 0.781131  [44864/60000]\n",
            "loss: 0.763551  [51264/60000]\n",
            "loss: 0.748422  [57664/60000]\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.714856  [   64/60000]\n",
            "loss: 0.814025  [ 6464/60000]\n",
            "loss: 0.572321  [12864/60000]\n",
            "loss: 0.790447  [19264/60000]\n",
            "loss: 0.690819  [25664/60000]\n",
            "loss: 0.683554  [32064/60000]\n",
            "loss: 0.773778  [38464/60000]\n",
            "loss: 0.766341  [44864/60000]\n",
            "loss: 0.744100  [51264/60000]\n",
            "loss: 0.728398  [57664/60000]\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.685092  [   64/60000]\n",
            "loss: 0.788296  [ 6464/60000]\n",
            "loss: 0.548226  [12864/60000]\n",
            "loss: 0.772776  [19264/60000]\n",
            "loss: 0.673026  [25664/60000]\n",
            "loss: 0.665530  [32064/60000]\n",
            "loss: 0.751920  [38464/60000]\n",
            "loss: 0.752962  [44864/60000]\n",
            "loss: 0.726980  [51264/60000]\n",
            "loss: 0.710186  [57664/60000]\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.658404  [   64/60000]\n",
            "loss: 0.764623  [ 6464/60000]\n",
            "loss: 0.527094  [12864/60000]\n",
            "loss: 0.757233  [19264/60000]\n",
            "loss: 0.657445  [25664/60000]\n",
            "loss: 0.650040  [32064/60000]\n",
            "loss: 0.731462  [38464/60000]\n",
            "loss: 0.740800  [44864/60000]\n",
            "loss: 0.711829  [51264/60000]\n",
            "loss: 0.693551  [57664/60000]\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.634336  [   64/60000]\n",
            "loss: 0.742875  [ 6464/60000]\n",
            "loss: 0.508446  [12864/60000]\n",
            "loss: 0.743405  [19264/60000]\n",
            "loss: 0.643673  [25664/60000]\n",
            "loss: 0.636717  [32064/60000]\n",
            "loss: 0.712320  [38464/60000]\n",
            "loss: 0.729721  [44864/60000]\n",
            "loss: 0.698396  [51264/60000]\n",
            "loss: 0.678178  [57664/60000]\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.612685  [   64/60000]\n",
            "loss: 0.722883  [ 6464/60000]\n",
            "loss: 0.491912  [12864/60000]\n",
            "loss: 0.730897  [19264/60000]\n",
            "loss: 0.631503  [25664/60000]\n",
            "loss: 0.625053  [32064/60000]\n",
            "loss: 0.694327  [38464/60000]\n",
            "loss: 0.719637  [44864/60000]\n",
            "loss: 0.686527  [51264/60000]\n",
            "loss: 0.663875  [57664/60000]\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.593099  [   64/60000]\n",
            "loss: 0.704529  [ 6464/60000]\n",
            "loss: 0.477091  [12864/60000]\n",
            "loss: 0.719472  [19264/60000]\n",
            "loss: 0.620668  [25664/60000]\n",
            "loss: 0.614931  [32064/60000]\n",
            "loss: 0.677423  [38464/60000]\n",
            "loss: 0.710580  [44864/60000]\n",
            "loss: 0.676108  [51264/60000]\n",
            "loss: 0.650447  [57664/60000]\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.575350  [   64/60000]\n",
            "loss: 0.687713  [ 6464/60000]\n",
            "loss: 0.463737  [12864/60000]\n",
            "loss: 0.709005  [19264/60000]\n",
            "loss: 0.611057  [25664/60000]\n",
            "loss: 0.606016  [32064/60000]\n",
            "loss: 0.661618  [38464/60000]\n",
            "loss: 0.702593  [44864/60000]\n",
            "loss: 0.666970  [51264/60000]\n",
            "loss: 0.637803  [57664/60000]\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.559157  [   64/60000]\n",
            "loss: 0.672319  [ 6464/60000]\n",
            "loss: 0.451714  [12864/60000]\n",
            "loss: 0.699248  [19264/60000]\n",
            "loss: 0.602403  [25664/60000]\n",
            "loss: 0.598013  [32064/60000]\n",
            "loss: 0.646844  [38464/60000]\n",
            "loss: 0.695647  [44864/60000]\n",
            "loss: 0.659034  [51264/60000]\n",
            "loss: 0.625937  [57664/60000]\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.544343  [   64/60000]\n",
            "loss: 0.658221  [ 6464/60000]\n",
            "loss: 0.440912  [12864/60000]\n",
            "loss: 0.690159  [19264/60000]\n",
            "loss: 0.594556  [25664/60000]\n",
            "loss: 0.590835  [32064/60000]\n",
            "loss: 0.633117  [38464/60000]\n",
            "loss: 0.689641  [44864/60000]\n",
            "loss: 0.652166  [51264/60000]\n",
            "loss: 0.614684  [57664/60000]\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.530841  [   64/60000]\n",
            "loss: 0.645336  [ 6464/60000]\n",
            "loss: 0.431125  [12864/60000]\n",
            "loss: 0.681579  [19264/60000]\n",
            "loss: 0.587323  [25664/60000]\n",
            "loss: 0.584290  [32064/60000]\n",
            "loss: 0.620342  [38464/60000]\n",
            "loss: 0.684607  [44864/60000]\n",
            "loss: 0.646251  [51264/60000]\n",
            "loss: 0.603913  [57664/60000]\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.518444  [   64/60000]\n",
            "loss: 0.633487  [ 6464/60000]\n",
            "loss: 0.422188  [12864/60000]\n",
            "loss: 0.673534  [19264/60000]\n",
            "loss: 0.580524  [25664/60000]\n",
            "loss: 0.578212  [32064/60000]\n",
            "loss: 0.608477  [38464/60000]\n",
            "loss: 0.680357  [44864/60000]\n",
            "loss: 0.641167  [51264/60000]\n",
            "loss: 0.593649  [57664/60000]\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.506965  [   64/60000]\n",
            "loss: 0.622590  [ 6464/60000]\n",
            "loss: 0.413898  [12864/60000]\n",
            "loss: 0.665958  [19264/60000]\n",
            "loss: 0.574120  [25664/60000]\n",
            "loss: 0.572499  [32064/60000]\n",
            "loss: 0.597535  [38464/60000]\n",
            "loss: 0.676923  [44864/60000]\n",
            "loss: 0.636722  [51264/60000]\n",
            "loss: 0.583822  [57664/60000]\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.496342  [   64/60000]\n",
            "loss: 0.612538  [ 6464/60000]\n",
            "loss: 0.406280  [12864/60000]\n",
            "loss: 0.658790  [19264/60000]\n",
            "loss: 0.567879  [25664/60000]\n",
            "loss: 0.567104  [32064/60000]\n",
            "loss: 0.587450  [38464/60000]\n",
            "loss: 0.674183  [44864/60000]\n",
            "loss: 0.632966  [51264/60000]\n",
            "loss: 0.574334  [57664/60000]\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.486413  [   64/60000]\n",
            "loss: 0.603214  [ 6464/60000]\n",
            "loss: 0.399234  [12864/60000]\n",
            "loss: 0.651910  [19264/60000]\n",
            "loss: 0.561812  [25664/60000]\n",
            "loss: 0.561875  [32064/60000]\n",
            "loss: 0.578120  [38464/60000]\n",
            "loss: 0.672059  [44864/60000]\n",
            "loss: 0.629684  [51264/60000]\n",
            "loss: 0.565167  [57664/60000]\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.477122  [   64/60000]\n",
            "loss: 0.594601  [ 6464/60000]\n",
            "loss: 0.392678  [12864/60000]\n",
            "loss: 0.645296  [19264/60000]\n",
            "loss: 0.555924  [25664/60000]\n",
            "loss: 0.556786  [32064/60000]\n",
            "loss: 0.569491  [38464/60000]\n",
            "loss: 0.670479  [44864/60000]\n",
            "loss: 0.626806  [51264/60000]\n",
            "loss: 0.556279  [57664/60000]\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.468416  [   64/60000]\n",
            "loss: 0.586555  [ 6464/60000]\n",
            "loss: 0.386567  [12864/60000]\n",
            "loss: 0.638891  [19264/60000]\n",
            "loss: 0.550100  [25664/60000]\n",
            "loss: 0.551773  [32064/60000]\n",
            "loss: 0.561568  [38464/60000]\n",
            "loss: 0.669326  [44864/60000]\n",
            "loss: 0.624301  [51264/60000]\n",
            "loss: 0.547681  [57664/60000]\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.460282  [   64/60000]\n",
            "loss: 0.578993  [ 6464/60000]\n",
            "loss: 0.380925  [12864/60000]\n",
            "loss: 0.632696  [19264/60000]\n",
            "loss: 0.544308  [25664/60000]\n",
            "loss: 0.546846  [32064/60000]\n",
            "loss: 0.554199  [38464/60000]\n",
            "loss: 0.668550  [44864/60000]\n",
            "loss: 0.622033  [51264/60000]\n",
            "loss: 0.539366  [57664/60000]\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.452603  [   64/60000]\n",
            "loss: 0.572033  [ 6464/60000]\n",
            "loss: 0.375648  [12864/60000]\n",
            "loss: 0.626692  [19264/60000]\n",
            "loss: 0.538657  [25664/60000]\n",
            "loss: 0.541974  [32064/60000]\n",
            "loss: 0.547366  [38464/60000]\n",
            "loss: 0.668077  [44864/60000]\n",
            "loss: 0.619897  [51264/60000]\n",
            "loss: 0.531386  [57664/60000]\n",
            "completed training in ... 266.77321910858154s\n",
            "starting timer for testing using CPU...\n",
            "Test Error: \n",
            " Accuracy: 81.0%, Avg loss: 0.545531 \n",
            "\n",
            "completed testing in ... 1.6622717380523682s\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import time\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Define linear model we will use below\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer, device):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn, device):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "# modified from https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
        "# get our competing devices ready ... go ahead and init all three here, but ONLY USE ONE during each test\n",
        "# scroll down below and replace the references to gpu_, tpu_, cpu with whichever device you are testing\n",
        "# make sure you replace ALL of them\n",
        "gpu_device = torch.device(\"cuda\")\n",
        "tpu_device = torch.device(\"xla\")\n",
        "cpu_device = torch.device(\"cpu\")\n",
        "\n",
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# first hyperparam\n",
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "# Show some sample data\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break\n",
        "\n",
        "\n",
        "# sample code for working with m1\n",
        "  # Create a Tensor directly on the mps device\n",
        "  #x = torch.ones(5, device=mps_device)\n",
        "  # Or\n",
        "  #x = torch.ones(5, device=\"mps\")\n",
        "  # Any operation happens on the GPU\n",
        "  #y = x * 2\n",
        "\n",
        "  # Move your model to mps just like any other device\n",
        "model = NeuralNetwork().to(device=gpu_device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "print(\"starting timer for training using CPU...\")\n",
        "start = time.time()\n",
        "epochs = 30 \n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer, device=gpu_device)\n",
        "print(f\"completed training in ... {time.time()-start}s\")\n",
        "\n",
        "print(\"starting timer for testing using CPU...\")\n",
        "start = time.time()\n",
        "test(test_dataloader, model, loss_fn, device=gpu_device)\n",
        "print(f\"completed testing in ... {time.time()-start}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TPU Run"
      ],
      "metadata": {
        "id": "haU5eJMRD2h2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSW-OnJxDzNY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Define linear model we will use below\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer, device):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn, device):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "# modified from https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
        "# get our competing devices ready ... go ahead and init all three here, but ONLY USE ONE during each test\n",
        "# scroll down below and replace the references to gpu_, tpu_, cpu with whichever device you are testing\n",
        "# make sure you replace ALL of them\n",
        "gpu_device = torch.device(\"cuda\")\n",
        "tpu_device = torch.device(\"xla\")\n",
        "cpu_device = torch.device(\"cpu\")\n",
        "\n",
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# first hyperparam\n",
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "# Show some sample data\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break\n",
        "\n",
        "\n",
        "# sample code for working with m1\n",
        "  # Create a Tensor directly on the mps device\n",
        "  #x = torch.ones(5, device=mps_device)\n",
        "  # Or\n",
        "  #x = torch.ones(5, device=\"mps\")\n",
        "  # Any operation happens on the GPU\n",
        "  #y = x * 2\n",
        "\n",
        "  # Move your model to mps just like any other device\n",
        "model = NeuralNetwork().to(device=tpu_device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "print(\"starting timer for training using CPU...\")\n",
        "start = time.time()\n",
        "epochs = 30 \n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer, device=tpu_device)\n",
        "print(f\"completed training in ... {time.time()-start}s\")\n",
        "\n",
        "print(\"starting timer for testing using CPU...\")\n",
        "start = time.time()\n",
        "test(test_dataloader, model, loss_fn, device=tpu_device)\n",
        "print(f\"completed testing in ... {time.time()-start}s\")"
      ]
    }
  ]
}